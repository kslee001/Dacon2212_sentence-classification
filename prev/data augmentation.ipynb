{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18b7fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from typing import Optional\n",
    "from tqdm import tqdm as tq\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, MarianMTModel, MarianTokenizer\n",
    "from transformers import logging\n",
    "import sentencepiece\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\"\n",
    "warnings.filterwarnings(action='ignore')\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# 임시 토크나이저\n",
    "from konlpy.tag import Okt, Komoran\n",
    "\n",
    "# Configuration\n",
    "CFG = {\n",
    "    'SEED':1203,\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':0.001,\n",
    "    'BATCH_SIZE':256,\n",
    "    'PLM':\"klue/roberta-large\",\n",
    "    'MAX_LEN':64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e997b63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv', 'test.csv', 'train.csv']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3813263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. num train : 13232\n",
      "\n",
      "2. null train check : \n",
      "ID       0\n",
      "문장       0\n",
      "유형       0\n",
      "극성       0\n",
      "시제       0\n",
      "확실성      0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "3. unique labels : \n",
      "['추론형' '사실형' '대화형' '예측형']\n",
      "[1709, 10852, 463, 208]\n",
      "['긍정' '부정' '미정']\n",
      "[12627, 464, 141]\n",
      "['현재' '미래' '과거']\n",
      "[5493, 1339, 6400]\n",
      "['확실' '불확실']\n",
      "[12142, 1090]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "folder = os.getcwd() + '/open'\n",
    "train = 'train.csv'\n",
    "test  = 'test.csv'\n",
    "submit = 'sample_submission.csv'\n",
    "train = pd.read_csv(folder + '/' + train)\n",
    "train, valid = train_test_split(train, test_size=0.2, random_state=CFG['SEED'])\n",
    "\n",
    "test = pd.read_csv(folder + '/' + test)\n",
    "submit = pd.read_csv(folder + '/' + submit)\n",
    "print(f\"1. num train : {len(train)}\\n\")\n",
    "print(f\"2. null train check : \\n{train.isnull().sum()}\\n\")\n",
    "print(f\"3. unique labels : \\n{train['유형'].unique()}\\n\\\n",
    "{[len(train[train['유형']==train['유형'].unique()[idx]]) for idx in range(len(train['유형'].unique()))]}\\n\\\n",
    "{train['극성'].unique()}\\n\\\n",
    "{[len(train[train['극성']==train['극성'].unique()[idx]]) for idx in range(len(train['극성'].unique()))]}\\n\\\n",
    "{train['시제'].unique()}\\n\\\n",
    "{[len(train[train['시제']==train['시제'].unique()[idx]]) for idx in range(len(train['시제'].unique()))]}\\n\\\n",
    "{train['확실성'].unique()}\\n\\\n",
    "{[len(train[train['확실성']==train['확실성'].unique()[idx]]) for idx in range(len(train['확실성'].unique()))]}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b40bab",
   "metadata": {},
   "source": [
    "### OpenNMT: Open-Source Toolkit for Neural Machine Translation  \n",
    "- https://arxiv.org/abs/1701.02810  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccbcd04c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, MarianMTModel, MarianTokenizer\n",
    "ko_to_en = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-tc-big-ko-en\")\n",
    "en_to_ko = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-tc-big-en-ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce9b4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, MarianMTModel, MarianTokenizer\n",
    "\n",
    "ko_to_en_tok = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-tc-big-ko-en\")\n",
    "en_to_ko_tok = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-tc-big-en-ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf9584b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "src_text = [\n",
    "    \"왜이렇게 번역 성능이 안좋은거야\"\n",
    "]\n",
    "translated = en_to_ko.generate(**en_to_ko_tok(src_text, return_tensors=\"pt\", padding=True))\n",
    "\n",
    "for t in translated:\n",
    "    print( en_to_ko_tok.decode(t, skip_special_tokens=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f5e3113",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': \"The translator doesn't work very well.\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-ko-en\")\n",
    "print(pipe(\"번역기가 성능이 안좋네\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08a91190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'ok 잘 얼굴'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-tc-big-en-ko\")\n",
    "print(pipe(\"what the fuck\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9339601d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e716167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_source = \"자고 싶어\"\n",
    "eng_translated = ko_to_en.generate(**ko_to_en_tok(korean_source, return_tensors=\"pt\", padding=True))\n",
    "[ko_to_en_tok.decode(t, skip_special_tokens=True) for t in eng_translated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5e70c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src_text = \"자고 싶어\"\n",
    "\n",
    "translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n",
    "[tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "ko_to_en = pipeline(\"text2text-generation\", model = \"circulus/kobart-trans-ko-en-v2\")\n",
    "en_to_ko = pipeline(\"text2text-generation\", model = \"circulus/kobart-trans-en-ko-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f158fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "ko_to_en = pipeline(\"text2text-generation\", model = \"Helsinki-NLP/opus-mt-ko-en\")\n",
    "# en_to_ko = pipeline(\"text2text-generation\", model = \"Helsinki-NLP/opus-mt-en-ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d3db21d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12964\\1682374443.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'문장'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfirst_translate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mko_to_en\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'generated_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_translate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "sample_text = train['문장'][90]\n",
    "print(sample_text)\n",
    "\n",
    "first_translate = ko_to_en(sample_text, max_length = 500)[0]['generated_text']\n",
    "print(first_translate)\n",
    "back_translate = en_to_ko(first_translate, max_length = 500)[0]['generated_text']\n",
    "print(back_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f30f34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_words = [\n",
    "    \"전망\", \"예보\", \"예측\", \"관측\", \"예정\", \"예상\", \"계획\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe41f9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963bfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05202745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5504c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8bac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f8e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97bee51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638563c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6087729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d492dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f5e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "src_text = [\n",
    "    \"2, 4, 6 등은 짝수이다.\",\n",
    "    \"네.\"\n",
    "]\n",
    "\n",
    "model_name = \"circulus/kobart-trans-ko-en-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "# translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n",
    "\n",
    "# for t in translated:\n",
    "#     print( tokenizer.decode(t, skip_special_tokens=True) )\n",
    "\n",
    "# expected output:\n",
    "#     2, 4, and 6 are even.\n",
    "#     Yeah.\n",
    "\n",
    "tokenizer.encode(src_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = \"자고 싶어.\"\n",
    "tokens = tokenizer(src_text)\n",
    "model(\n",
    "    input_ids=torch.tensor(tokens['input_ids']).reshape(1, -1), \n",
    "    attention_mask=torch.tensor(tokens['attention_mask']).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60270bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "src_text = [\n",
    "    \"2, 4, and 6 are even.\",\n",
    "    \"Yeah.\"\n",
    "]\n",
    "\n",
    "model_name = \"circulus/kobart-trans-en-ko-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n",
    "\n",
    "for t in translated:\n",
    "    print( tokenizer.decode(t, skip_special_tokens=True) )\n",
    "\n",
    "# expected output:\n",
    "#     2, 4, and 6 are even.\n",
    "#     Yeah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = [\n",
    "    \"2, 4, 6 등은 짝수이다.\",\n",
    "    \"네.\"\n",
    "]\n",
    "translated = ko_to_en.generate(**ko_to_en_tokenizer(src_text, return_tensors=\"pt\", padding=True))\n",
    "\n",
    "for t in translated:\n",
    "    print( ko_to_en_tokenizer.decode(t, skip_special_tokens=True) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f654a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tch",
   "language": "python",
   "name": "tch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
