{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e1c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from tqdm import tqdm as tq\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "# 임시 토크나이저\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e00ea1",
   "metadata": {},
   "source": [
    "## check train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6f8456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID         label\n",
       "0  TEST_0000  추론형-긍정-현재-확실\n",
       "1  TEST_0001  추론형-긍정-현재-확실\n",
       "2  TEST_0002  추론형-긍정-현재-확실\n",
       "3  TEST_0003  추론형-긍정-현재-확실\n",
       "4  TEST_0004  추론형-긍정-현재-확실"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = os.getcwd() + '\\\\open'\n",
    "train = os.listdir(folder)[2]\n",
    "test  = os.listdir(folder)[1]\n",
    "submit = os.listdir(folder)[0]\n",
    "\n",
    "train = pd.read_csv(folder + '/' + train)\n",
    "test = pd.read_csv(folder + '/' + test)\n",
    "submit = pd.read_csv(folder + '/' + submit)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5db3db5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. num train : 7090\n",
      "\n",
      "2. null train check : \n",
      "ID       0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '유형'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. num train : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. null train check : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrain\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. unique labels : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrain\u001b[38;5;241m.\u001b[39m유형\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;28mlen\u001b[39m(train[train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m유형\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtrain\u001b[38;5;241m.\u001b[39m유형\u001b[38;5;241m.\u001b[39munique()[idx]]) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train\u001b[38;5;241m.\u001b[39m유형\u001b[38;5;241m.\u001b[39munique()))]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mtrain\u001b[38;5;241m.\u001b[39m극성\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;28mlen\u001b[39m(train[train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m극성\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtrain\u001b[38;5;241m.\u001b[39m극성\u001b[38;5;241m.\u001b[39munique()[idx]]) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train\u001b[38;5;241m.\u001b[39m극성\u001b[38;5;241m.\u001b[39munique()))]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mtrain\u001b[38;5;241m.\u001b[39m시제\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;28mlen\u001b[39m(train[train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m시제\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtrain\u001b[38;5;241m.\u001b[39m시제\u001b[38;5;241m.\u001b[39munique()[idx]]) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train\u001b[38;5;241m.\u001b[39m시제\u001b[38;5;241m.\u001b[39munique()))]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mtrain\u001b[38;5;241m.\u001b[39m확실성\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;28mlen\u001b[39m(train[train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m확실성\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mtrain\u001b[38;5;241m.\u001b[39m확실성\u001b[38;5;241m.\u001b[39munique()[idx]]) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train\u001b[38;5;241m.\u001b[39m확실성\u001b[38;5;241m.\u001b[39munique()))]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:5907\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5901\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5902\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5903\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5904\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5905\u001b[0m ):\n\u001b[0;32m   5906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '유형'"
     ]
    }
   ],
   "source": [
    "print(f\"1. num train : {len(train)}\\n\")\n",
    "print(f\"2. null train check : \\n{train.isnull().sum()}\\n\")\n",
    "print(f\"3. unique labels : \\n{train.유형.unique()}\\n\\\n",
    "{[len(train[train['유형']==train.유형.unique()[idx]]) for idx in range(len(train.유형.unique()))]}\\n\\\n",
    "{train.극성.unique()}\\n\\\n",
    "{[len(train[train['극성']==train.극성.unique()[idx]]) for idx in range(len(train.극성.unique()))]}\\n\\\n",
    "{train.시제.unique()}\\n\\\n",
    "{[len(train[train['시제']==train.시제.unique()[idx]]) for idx in range(len(train.시제.unique()))]}\\n\\\n",
    "{train.확실성.unique()}\\n\\\n",
    "{[len(train[train['확실성']==train.확실성.unique()[idx]]) for idx in range(len(train.확실성.unique()))]}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e7941b",
   "metadata": {},
   "source": [
    "## train data 둘러보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce4ad81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16541"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = train.문장.tolist()\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "045babca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 16541/16541 [00:00<00:00, 688321.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "for text in tq(texts):\n",
    "    lengths.append(len(text.split(' ')))\n",
    "lengths = pd.DataFrame(sorted(lengths))    \n",
    "lengths[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae979e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16539</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16540</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "16539   94\n",
       "16540  124"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths[lengths[0]>=80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c39b0a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 22,\n",
       " 12,\n",
       " 18,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 18,\n",
       " 10,\n",
       " 11,\n",
       " 16,\n",
       " 9,\n",
       " 14,\n",
       " 27,\n",
       " 16,\n",
       " 13,\n",
       " 12,\n",
       " 8,\n",
       " 8,\n",
       " 30,\n",
       " 14,\n",
       " 16,\n",
       " 23,\n",
       " 10,\n",
       " 45,\n",
       " 26,\n",
       " 17,\n",
       " 10,\n",
       " 15,\n",
       " 8,\n",
       " 4,\n",
       " 14,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 17,\n",
       " 28,\n",
       " 31,\n",
       " 5,\n",
       " 11,\n",
       " 14,\n",
       " 4,\n",
       " 14,\n",
       " 21,\n",
       " 14,\n",
       " 23,\n",
       " 15,\n",
       " 20,\n",
       " 14,\n",
       " 29,\n",
       " 11,\n",
       " 8,\n",
       " 7,\n",
       " 25,\n",
       " 8,\n",
       " 9,\n",
       " 17,\n",
       " 13,\n",
       " 17,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 15,\n",
       " 21,\n",
       " 28,\n",
       " 8,\n",
       " 23,\n",
       " 21,\n",
       " 16,\n",
       " 7,\n",
       " 15,\n",
       " 32,\n",
       " 11,\n",
       " 14,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 16,\n",
       " 12,\n",
       " 5,\n",
       " 20,\n",
       " 24,\n",
       " 10,\n",
       " 15,\n",
       " 16,\n",
       " 9,\n",
       " 5,\n",
       " 34,\n",
       " 5,\n",
       " 7,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 10,\n",
       " 11,\n",
       " 8,\n",
       " 10,\n",
       " 13,\n",
       " 15,\n",
       " 34,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 33,\n",
       " 3,\n",
       " 14,\n",
       " 12,\n",
       " 11,\n",
       " 10,\n",
       " 17,\n",
       " 11,\n",
       " 11,\n",
       " 17,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 12,\n",
       " 20,\n",
       " 11,\n",
       " 7,\n",
       " 12,\n",
       " 24,\n",
       " 30,\n",
       " 8,\n",
       " 15,\n",
       " 14,\n",
       " 9,\n",
       " 2,\n",
       " 18,\n",
       " 14,\n",
       " 28,\n",
       " 22,\n",
       " 40,\n",
       " 15,\n",
       " 12,\n",
       " 7,\n",
       " 14,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 19,\n",
       " 9,\n",
       " 16,\n",
       " 10,\n",
       " 13,\n",
       " 5,\n",
       " 14,\n",
       " 7,\n",
       " 10,\n",
       " 14,\n",
       " 12,\n",
       " 33,\n",
       " 17,\n",
       " 7,\n",
       " 23,\n",
       " 4,\n",
       " 12,\n",
       " 13,\n",
       " 8,\n",
       " 15,\n",
       " 15,\n",
       " 5,\n",
       " 37,\n",
       " 25,\n",
       " 12,\n",
       " 9,\n",
       " 15,\n",
       " 17,\n",
       " 10,\n",
       " 30,\n",
       " 10,\n",
       " 12,\n",
       " 20,\n",
       " 41,\n",
       " 6,\n",
       " 22,\n",
       " 19,\n",
       " 5,\n",
       " 18,\n",
       " 9,\n",
       " 21,\n",
       " 24,\n",
       " 10,\n",
       " 16,\n",
       " 37,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 9,\n",
       " 38,\n",
       " 9,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 7,\n",
       " 6,\n",
       " 23,\n",
       " 7,\n",
       " 14,\n",
       " 18,\n",
       " 22,\n",
       " 17,\n",
       " 17,\n",
       " 16,\n",
       " 14,\n",
       " 14,\n",
       " 7,\n",
       " 7,\n",
       " 22,\n",
       " 13,\n",
       " 7,\n",
       " 13,\n",
       " 16,\n",
       " 19,\n",
       " 15,\n",
       " 17,\n",
       " 8,\n",
       " 14,\n",
       " 5,\n",
       " 5,\n",
       " 12,\n",
       " 28,\n",
       " 18,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 13,\n",
       " 5,\n",
       " 17,\n",
       " 24,\n",
       " 18,\n",
       " 22,\n",
       " 17,\n",
       " 25,\n",
       " 8,\n",
       " 16,\n",
       " 13,\n",
       " 10,\n",
       " 13,\n",
       " 10,\n",
       " 17,\n",
       " 17,\n",
       " 25,\n",
       " 10,\n",
       " 15,\n",
       " 6,\n",
       " 25,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 21,\n",
       " 20,\n",
       " 9,\n",
       " 3,\n",
       " 15,\n",
       " 10,\n",
       " 13,\n",
       " 22,\n",
       " 14,\n",
       " 16,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 23,\n",
       " 8,\n",
       " 14,\n",
       " 16,\n",
       " 14,\n",
       " 4,\n",
       " 7,\n",
       " 24,\n",
       " 8,\n",
       " 21,\n",
       " 12,\n",
       " 11,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 21,\n",
       " 10,\n",
       " 4,\n",
       " 11,\n",
       " 3,\n",
       " 23,\n",
       " 11,\n",
       " 5,\n",
       " 12,\n",
       " 24,\n",
       " 17,\n",
       " 7,\n",
       " 14,\n",
       " 8,\n",
       " 30,\n",
       " 9,\n",
       " 7,\n",
       " 16,\n",
       " 11,\n",
       " 7,\n",
       " 11,\n",
       " 4,\n",
       " 8,\n",
       " 12,\n",
       " 12,\n",
       " 9,\n",
       " 19,\n",
       " 19,\n",
       " 6,\n",
       " 16,\n",
       " 8,\n",
       " 15,\n",
       " 11,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 28,\n",
       " 10,\n",
       " 4,\n",
       " 14,\n",
       " 12,\n",
       " 7,\n",
       " 8,\n",
       " 12,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 17,\n",
       " 31,\n",
       " 32,\n",
       " 17,\n",
       " 21,\n",
       " 33,\n",
       " 9,\n",
       " 13,\n",
       " 28,\n",
       " 10,\n",
       " 8,\n",
       " 16,\n",
       " 17,\n",
       " 6,\n",
       " 27,\n",
       " 19,\n",
       " 13,\n",
       " 12,\n",
       " 8,\n",
       " 26,\n",
       " 12,\n",
       " 15,\n",
       " 7,\n",
       " 20,\n",
       " 37,\n",
       " 6,\n",
       " 11,\n",
       " 5,\n",
       " 14,\n",
       " 17,\n",
       " 5,\n",
       " 18,\n",
       " 24,\n",
       " 22,\n",
       " 24,\n",
       " 20,\n",
       " 17,\n",
       " 30,\n",
       " 5,\n",
       " 9,\n",
       " 13,\n",
       " 23,\n",
       " 10,\n",
       " 15,\n",
       " 18,\n",
       " 12,\n",
       " 11,\n",
       " 14,\n",
       " 17,\n",
       " 8,\n",
       " 11,\n",
       " 16,\n",
       " 13,\n",
       " 20,\n",
       " 14,\n",
       " 3,\n",
       " 11,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 17,\n",
       " 19,\n",
       " 16,\n",
       " 6,\n",
       " 11,\n",
       " 30,\n",
       " 18,\n",
       " 10,\n",
       " 11,\n",
       " 8,\n",
       " 22,\n",
       " 21,\n",
       " 15,\n",
       " 17,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 16,\n",
       " 11,\n",
       " 19,\n",
       " 22,\n",
       " 18,\n",
       " 13,\n",
       " 10,\n",
       " 8,\n",
       " 13,\n",
       " 6,\n",
       " 20,\n",
       " 21,\n",
       " 6,\n",
       " 5,\n",
       " 21,\n",
       " 12,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 30,\n",
       " 15,\n",
       " 5,\n",
       " 21,\n",
       " 22,\n",
       " 16,\n",
       " 9,\n",
       " 25,\n",
       " 17,\n",
       " 7,\n",
       " 9,\n",
       " 14,\n",
       " 4,\n",
       " 15,\n",
       " 17,\n",
       " 15,\n",
       " 27,\n",
       " 16,\n",
       " 13,\n",
       " 34,\n",
       " 22,\n",
       " 11,\n",
       " 8,\n",
       " 27,\n",
       " 71,\n",
       " 20,\n",
       " 20,\n",
       " 9,\n",
       " 19,\n",
       " 5,\n",
       " 11,\n",
       " 16,\n",
       " 11,\n",
       " 20,\n",
       " 22,\n",
       " 12,\n",
       " 26,\n",
       " 12,\n",
       " 13,\n",
       " 26,\n",
       " 6,\n",
       " 22,\n",
       " 11,\n",
       " 4,\n",
       " 7,\n",
       " 26,\n",
       " 8,\n",
       " 17,\n",
       " 16,\n",
       " 9,\n",
       " 18,\n",
       " 26,\n",
       " 3,\n",
       " 21,\n",
       " 38,\n",
       " 19,\n",
       " 13,\n",
       " 13,\n",
       " 7,\n",
       " 12,\n",
       " 4,\n",
       " 4,\n",
       " 10,\n",
       " 9,\n",
       " 20,\n",
       " 12,\n",
       " 9,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 22,\n",
       " 16,\n",
       " 33,\n",
       " 21,\n",
       " 8,\n",
       " 11,\n",
       " 6,\n",
       " 38,\n",
       " 14,\n",
       " 34,\n",
       " 10,\n",
       " 15,\n",
       " 21,\n",
       " 18,\n",
       " 18,\n",
       " 24,\n",
       " 22,\n",
       " 12,\n",
       " 26,\n",
       " 3,\n",
       " 10,\n",
       " 14,\n",
       " 6,\n",
       " 17,\n",
       " 18,\n",
       " 35,\n",
       " 36,\n",
       " 18,\n",
       " 9,\n",
       " 14,\n",
       " 6,\n",
       " 17,\n",
       " 19,\n",
       " 6,\n",
       " 5,\n",
       " 15,\n",
       " 13,\n",
       " 9,\n",
       " 20,\n",
       " 5,\n",
       " 14,\n",
       " 12,\n",
       " 35,\n",
       " 10,\n",
       " 14,\n",
       " 12,\n",
       " 12,\n",
       " 16,\n",
       " 8,\n",
       " 18,\n",
       " 13,\n",
       " 16,\n",
       " 6,\n",
       " 9,\n",
       " 21,\n",
       " 22,\n",
       " 13,\n",
       " 14,\n",
       " 7,\n",
       " 21,\n",
       " 20,\n",
       " 26,\n",
       " 8,\n",
       " 9,\n",
       " 22,\n",
       " 15,\n",
       " 15,\n",
       " 10,\n",
       " 18,\n",
       " 15,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 7,\n",
       " 18,\n",
       " 9,\n",
       " 17,\n",
       " 9,\n",
       " 5,\n",
       " 27,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 14,\n",
       " 13,\n",
       " 24,\n",
       " 5,\n",
       " 11,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 18,\n",
       " 11,\n",
       " 8,\n",
       " 22,\n",
       " 48,\n",
       " 11,\n",
       " 4,\n",
       " 13,\n",
       " 11,\n",
       " 22,\n",
       " 11,\n",
       " 15,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 19,\n",
       " 6,\n",
       " 16,\n",
       " 5,\n",
       " 10,\n",
       " 27,\n",
       " 14,\n",
       " 10,\n",
       " 18,\n",
       " 17,\n",
       " 17,\n",
       " 15,\n",
       " 22,\n",
       " 15,\n",
       " 18,\n",
       " 7,\n",
       " 17,\n",
       " 17,\n",
       " 14,\n",
       " 12,\n",
       " 10,\n",
       " 22,\n",
       " 31,\n",
       " 19,\n",
       " 17,\n",
       " 10,\n",
       " 19,\n",
       " 24,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 19,\n",
       " 10,\n",
       " 10,\n",
       " 21,\n",
       " 15,\n",
       " 8,\n",
       " 20,\n",
       " 6,\n",
       " 23,\n",
       " 18,\n",
       " 11,\n",
       " 31,\n",
       " 20,\n",
       " 10,\n",
       " 22,\n",
       " 26,\n",
       " 10,\n",
       " 13,\n",
       " 9,\n",
       " 9,\n",
       " 12,\n",
       " 23,\n",
       " 28,\n",
       " 18,\n",
       " 10,\n",
       " 10,\n",
       " 20,\n",
       " 7,\n",
       " 3,\n",
       " 19,\n",
       " 23,\n",
       " 27,\n",
       " 11,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 24,\n",
       " 14,\n",
       " 21,\n",
       " 27,\n",
       " 13,\n",
       " 16,\n",
       " 9,\n",
       " 36,\n",
       " 19,\n",
       " 6,\n",
       " 7,\n",
       " 14,\n",
       " 13,\n",
       " 6,\n",
       " 20,\n",
       " 10,\n",
       " 14,\n",
       " 32,\n",
       " 6,\n",
       " 33,\n",
       " 17,\n",
       " 19,\n",
       " 14,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 14,\n",
       " 12,\n",
       " 13,\n",
       " 6,\n",
       " 10,\n",
       " 25,\n",
       " 11,\n",
       " 16,\n",
       " 8,\n",
       " 13,\n",
       " 12,\n",
       " 6,\n",
       " 16,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 12,\n",
       " 10,\n",
       " 2,\n",
       " 9,\n",
       " 17,\n",
       " 17,\n",
       " 13,\n",
       " 26,\n",
       " 7,\n",
       " 15,\n",
       " 12,\n",
       " 3,\n",
       " 12,\n",
       " 7,\n",
       " 25,\n",
       " 9,\n",
       " 20,\n",
       " 10,\n",
       " 8,\n",
       " 12,\n",
       " 9,\n",
       " 21,\n",
       " 12,\n",
       " 9,\n",
       " 11,\n",
       " 16,\n",
       " 7,\n",
       " 16,\n",
       " 19,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 7,\n",
       " 14,\n",
       " 4,\n",
       " 11,\n",
       " 8,\n",
       " 35,\n",
       " 20,\n",
       " 8,\n",
       " 13,\n",
       " 12,\n",
       " 20,\n",
       " 15,\n",
       " 18,\n",
       " 14,\n",
       " 11,\n",
       " 15,\n",
       " 35,\n",
       " 9,\n",
       " 29,\n",
       " 17,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 18,\n",
       " 21,\n",
       " 7,\n",
       " 19,\n",
       " 15,\n",
       " 10,\n",
       " 24,\n",
       " 16,\n",
       " 10,\n",
       " 28,\n",
       " 17,\n",
       " 21,\n",
       " 6,\n",
       " 13,\n",
       " 28,\n",
       " 16,\n",
       " 12,\n",
       " 22,\n",
       " 8,\n",
       " 16,\n",
       " 12,\n",
       " 15,\n",
       " 40,\n",
       " 15,\n",
       " 25,\n",
       " 28,\n",
       " 9,\n",
       " 11,\n",
       " 8,\n",
       " 21,\n",
       " 10,\n",
       " 6,\n",
       " 19,\n",
       " 14,\n",
       " 11,\n",
       " 5,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 28,\n",
       " 5,\n",
       " 15,\n",
       " 12,\n",
       " 16,\n",
       " 17,\n",
       " 20,\n",
       " 12,\n",
       " 15,\n",
       " 15,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 16,\n",
       " 6,\n",
       " 36,\n",
       " 16,\n",
       " 9,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 14,\n",
       " 7,\n",
       " 21,\n",
       " 9,\n",
       " 21,\n",
       " 13,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 34,\n",
       " 16,\n",
       " 13,\n",
       " 7,\n",
       " 19,\n",
       " 8,\n",
       " 13,\n",
       " 12,\n",
       " 9,\n",
       " 19,\n",
       " 11,\n",
       " 16,\n",
       " 26,\n",
       " 16,\n",
       " 14,\n",
       " 17,\n",
       " 9,\n",
       " 21,\n",
       " 20,\n",
       " 14,\n",
       " 12,\n",
       " 8,\n",
       " 11,\n",
       " 14,\n",
       " 15,\n",
       " 10,\n",
       " 18,\n",
       " 10,\n",
       " 28,\n",
       " 20,\n",
       " 12,\n",
       " 8,\n",
       " 7,\n",
       " 15,\n",
       " 17,\n",
       " 17,\n",
       " 28,\n",
       " 12,\n",
       " 26,\n",
       " 8,\n",
       " 13,\n",
       " 19,\n",
       " 12,\n",
       " 8,\n",
       " 12,\n",
       " 32,\n",
       " 11,\n",
       " 17,\n",
       " 14,\n",
       " 10,\n",
       " 20,\n",
       " 14,\n",
       " 6,\n",
       " 17,\n",
       " 17,\n",
       " 8,\n",
       " 6,\n",
       " 40,\n",
       " 7,\n",
       " 20,\n",
       " 10,\n",
       " 13,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 14,\n",
       " 10,\n",
       " 18,\n",
       " 12,\n",
       " 4,\n",
       " 19,\n",
       " 6,\n",
       " 13,\n",
       " 17,\n",
       " 13,\n",
       " 20,\n",
       " 18,\n",
       " 7,\n",
       " 11,\n",
       " 23,\n",
       " 16,\n",
       " 27,\n",
       " 6,\n",
       " 14,\n",
       " 26,\n",
       " 3,\n",
       " 11,\n",
       " 20,\n",
       " 7,\n",
       " 36,\n",
       " 35,\n",
       " 7,\n",
       " 22,\n",
       " 9,\n",
       " 25,\n",
       " 21,\n",
       " 17,\n",
       " 8,\n",
       " 11,\n",
       " 7,\n",
       " 13,\n",
       " 28,\n",
       " 15,\n",
       " 7,\n",
       " 8,\n",
       " 16,\n",
       " 9,\n",
       " 14,\n",
       " 23,\n",
       " 9,\n",
       " 16,\n",
       " 18,\n",
       " 27,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 20,\n",
       " 10,\n",
       " 41,\n",
       " 46,\n",
       " 10,\n",
       " 33,\n",
       " 31,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 23,\n",
       " 9,\n",
       " 11,\n",
       " 17,\n",
       " 15,\n",
       " 43,\n",
       " 12,\n",
       " 21,\n",
       " 16,\n",
       " 15,\n",
       " 11,\n",
       " 16,\n",
       " 45,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 25,\n",
       " 10,\n",
       " 27,\n",
       " 14,\n",
       " 17,\n",
       " 10,\n",
       " 9,\n",
       " 31,\n",
       " 10,\n",
       " 14,\n",
       " 17,\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['유형']=='대화형']['문장'].tolist()[74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['유형']=='사실형']['문장'].tolist()[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['유형']=='예측형'].iloc[76]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de0a4cb",
   "metadata": {},
   "source": [
    "- 예측형  \n",
    "  - 전망, 예보, 예측, 예정, 예상, 계획, ㄹ-것이다, ㄹ-것으로, -겠다, 가능성, 보인다\n",
    "  \n",
    "- 대화형  \n",
    "  - 니다, -까, -죠, -요, -인가, -더라, -하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7fbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59a6db91",
   "metadata": {},
   "source": [
    "## find frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c704800",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
    "noun_ext = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbebb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcounter(data:pd.Series, mode='noun', threshold=30, visible_tqdm = True):\n",
    "    dic = dict()\n",
    "    noun_ext = Okt()\n",
    "\n",
    "    if mode == 'noun':\n",
    "        func = noun_ext.nouns\n",
    "    elif mode == 'pos':\n",
    "        func = noun_ext.pos\n",
    "    else:\n",
    "        func = noun_ext.morphs\n",
    "    \n",
    "    if visible_tqdm is not None:\n",
    "        iterator = tq(enumerate(data), total=len(data))\n",
    "    else:\n",
    "        iterator = enumerate(data)\n",
    "    \n",
    "\n",
    "    for idx, text in iterator:\n",
    "        nouns = func(text)\n",
    "\n",
    "        for word in nouns:\n",
    "            if len(word) <= 1 :\n",
    "                continue \n",
    "            if word in dic:\n",
    "                dic[word] += 1\n",
    "            else:\n",
    "                dic[word] = 1 \n",
    "\n",
    "                    \n",
    "    freq_all = sorted(dic.items(), key = lambda item: item[1], reverse = True)                \n",
    "    freq = []\n",
    "    \n",
    "    # threshold 이하는 다 쳐내\n",
    "    for item in freq_all:\n",
    "        if item[1] < threshold:\n",
    "            continue\n",
    "        freq.append(item)\n",
    "    \n",
    "    freq = freq[:50]\n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878af56d",
   "metadata": {},
   "source": [
    "### frequent words of each \"type\" of text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01fe67",
   "metadata": {},
   "source": [
    "##### (1) 사실형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ded773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "사실형 = train[train['유형']=='사실형']['문장'].tolist()\n",
    "사실형 = wordcounter(사실형, mode=None, visible_tqdm=True)\n",
    "사실형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e157a",
   "metadata": {},
   "source": [
    "##### (2) 추론형 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be068749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "추론형 = train[train['유형']=='추론형']['문장'].tolist()\n",
    "추론형 = wordcounter(추론형, True)\n",
    "추론형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510568e8",
   "metadata": {},
   "source": [
    "##### (3) 예측형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d12702",
   "metadata": {},
   "outputs": [],
   "source": [
    "예측형 = train[train['유형']=='예측형']['문장'].tolist()\n",
    "예측형 = wordcounter(예측형, True)\n",
    "예측형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02df862",
   "metadata": {},
   "source": [
    "##### (4) 대화형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "대화형 = train[train['유형']=='대화형']['문장'].tolist()\n",
    "대화형 = wordcounter(대화형, True)\n",
    "대화형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4518a7",
   "metadata": {},
   "source": [
    "### frequent words of each \"polarity\" of text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6db1b5",
   "metadata": {},
   "source": [
    "##### (1) 긍정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226981c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "긍정 = train[train['극성']=='긍정']['문장'].tolist()\n",
    "긍정 = wordcounter(긍정, mode=None, visible_tqdm=True)\n",
    "긍정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c15a0",
   "metadata": {},
   "source": [
    "##### (2) 부정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "부정 = train[train['극성']=='부정']['문장'].tolist()\n",
    "부정 = wordcounter(부정, mode=None, visible_tqdm=True)\n",
    "부정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa1a7e",
   "metadata": {},
   "source": [
    "##### (3) 미정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068aaf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "미정 = train[train['극성']=='미정']['문장'].tolist()\n",
    "미정 = wordcounter(미정, mode=None, visible_tqdm=True)\n",
    "미정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c3efd",
   "metadata": {},
   "source": [
    "### frequent words of each \"tense\" of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b817fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "현재 = train[train['시제']=='현재']['문장'].tolist()\n",
    "현재 = wordcounter(현재, mode=None, visible_tqdm=True)\n",
    "현재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4694a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "과거 = train[train['시제']=='과거']['문장'].tolist()\n",
    "과거 = wordcounter(과거, mode=None, visible_tqdm=True)\n",
    "과거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab2213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "미래 = train[train['시제']=='미래']['문장'].tolist()\n",
    "미래 = wordcounter(미래, mode=None, visible_tqdm=True)\n",
    "미래"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f17929f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7d34b0e",
   "metadata": {},
   "source": [
    "### check test data\n",
    "- weighted F1 score  \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310370ee",
   "metadata": {},
   "source": [
    "### check submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3bf874",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af139a3",
   "metadata": {},
   "source": [
    "### pretrained model  \n",
    "- 논문으로 공개된 사전 학습 모델(Pre-trained Model) 사용 가능  \n",
    "- KLUE roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d1e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, max_len, plm=\"klue/roberta-large\", infer=False):\n",
    "        self.text      = data['문장'].tolist()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(plm)\n",
    "        self.max_len   = max_len\n",
    "        self.infer     = infer\n",
    "        \n",
    "        if self.infer is not None:\n",
    "            type1 = data['유형']=='사실형'\n",
    "            type2 = data['유형']=='추론형'\n",
    "            type3 = data['유형']=='예측형'\n",
    "            type4 = data['유형']=='대화형'\n",
    "            \n",
    "            sent1 = data['극성']=='긍정'\n",
    "            sent2 = data['극성']=='부정'\n",
    "            sent3 = data['극성']=='미정'\n",
    "            \n",
    "            tense1 = data['시제']=='현재'\n",
    "            tense2 = data['시제']=='과거'\n",
    "            tense3 = data['시제']=='미래'\n",
    "            \n",
    "            certainty1 = data['확실성']=='확실'\n",
    "            certainty2 = data['확실성']=='불확실'\n",
    "            \n",
    "            self.y1 = np.where(type1, 0, \n",
    "                      np.where(type2, 1, \n",
    "                      np.where(type3, 2, 3))).tolist()\n",
    "            self.y2 = np.where(sent1, 0,\n",
    "                      np.where(sent2, 1, 2)).tolist()\n",
    "            self.y3 = np.where(tense1, 0, \n",
    "                      np.where(tense2, 1, 2)).tolist()\n",
    "            self.y4 = np.where(certainty1, 0, 1).tolist()\n",
    "                        \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        x_ids, x_attn = [encoding['input_ids'].flatten(), encoding['attention_mask'].flatten()]\n",
    "        if self.infer is not None:\n",
    "            y1 = self.y1[idx]\n",
    "            y2 = self.y2[idx]\n",
    "            y3 = self.y3[idx]\n",
    "            y4 = self.y4[idx]\n",
    "            \n",
    "            ys = torch.tensor([y1,y2,y3,y4]) \n",
    "            return x_ids, x_attn, ys        \n",
    "        else:\n",
    "            return x_ids, x_attn\n",
    "            \n",
    "def get_dataloader(data, batch_size, max_len=256, plm=\"klue/roberta-large\", infer=False, shuffle=True):\n",
    "    return DataLoader(\n",
    "        dataset=CustomDataset(data=data, max_len=max_len, plm=plm, infer=infer),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787188bf",
   "metadata": {},
   "source": [
    "### data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93b375fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, plm = \"klue/roberta-large\"):\n",
    "        super().__init__()\n",
    "        self.activate = torch.nn.SiLU()\n",
    "        self.dropout = torch.nn.Dropout(p=0.1)\n",
    "        self.feature_extractor = AutoModel.from_pretrained(plm)\n",
    "        self.feature_extractor.eval() # freeze FE \n",
    "    \n",
    "        self.type_linear      = self.get_cls()\n",
    "        self.polarity_linear  = self.get_cls()\n",
    "        self.tense_linear     = self.get_cls()\n",
    "        self.certainty_linear = self.get_cls()\n",
    "            \n",
    "    def forward(self, x_ids, x_attn):  \n",
    "        \n",
    "        x = self.feature_extractor(input_ids=x_ids, attention_mask=x_attn).to_tuple()[0] [:, 0, :] # cls token\n",
    "                                                                                    # hidden states:0 / last hidden state:1\n",
    "        y1 = self.type_linear(x)\n",
    "        y2 = self.polarity_linear(x)\n",
    "        y3 = self.tense_linear(x)\n",
    "        y4 = self.certainty_linear(x)\n",
    "    \n",
    "        return (y1,y2,y3,y4)\n",
    "\n",
    "    def get_cls(self):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Linear(1024, 768),\n",
    "            torch.nn.LayerNorm(768),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            self.activate,\n",
    "            torch.nn.Linear(768, 256),\n",
    "            torch.nn.LayerNorm(256),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            self.activate,\n",
    "            torch.nn.Linear(256, 1)\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d63a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':256,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51571c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_dataloader(\n",
    "    data=train,\n",
    "    batch_size=CFG['BATCH_SIZE']\n",
    ")\n",
    "\n",
    "model = Classifier()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d947b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterions = [torch.nn.CrossEntropyLoss() for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf471ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/65 [00:49<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14508\\3579286676.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0myhat0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_attn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcriterions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14508\\613893378.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_ids, x_attn)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_attn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_attn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# cls token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                                                                                     \u001b[1;31m# hidden states:0 / last hidden state:1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_linear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    842\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m         )\n\u001b[1;32m--> 844\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    845\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    518\u001b[0m                 )\n\u001b[0;32m    519\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    521\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    406\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[1;32m--> 332\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mattention_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;31m# Mask heads if we want to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[1;34m\"but got {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = model.to(device)\n",
    "criterions = [torch.nn.CrossEntropyLoss().to(device) for _ in range(4)]\n",
    "\n",
    "for epoch in range(1, CFG['EPOCHS']+1):\n",
    "    model.train()\n",
    "    train_loss=[]\n",
    "    for x_ids, x_attn, y in tq(train_loader):\n",
    "        x_ids, x_attn, y = x_ids.to(device), x_attn.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        yhat0, yhat1, yhat2, yhat3 = model(x_ids, x_attn)\n",
    "        \n",
    "        loss1 = 0.25*criterions[0](yhat0, y[0])\n",
    "        loss2 = 0.25*criterions[1](yhat1, y[1])\n",
    "        loss3 = 0.25*criterions[2](yhat2, y[2])\n",
    "        loss4 = 0.25*criterions[3](yhat3, y[3])\n",
    "        \n",
    "        loss = loss1+loss2+loss3+loss4\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ed1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tch",
   "language": "python",
   "name": "tch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
