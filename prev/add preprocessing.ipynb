{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e1c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from itertools import zip_longest\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from tqdm import tqdm as tq\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "# 임시 토크나이저\n",
    "from konlpy.tag import Okt, Komoran"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e00ea1",
   "metadata": {},
   "source": [
    "## check train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6f8456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>문장</th>\n",
       "      <th>유형</th>\n",
       "      <th>극성</th>\n",
       "      <th>시제</th>\n",
       "      <th>확실성</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>미래</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                                 문장   유형  극성  \\\n",
       "0  TRAIN_00000              0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.  사실형  긍정   \n",
       "1  TRAIN_00001  이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...  사실형  긍정   \n",
       "2  TRAIN_00002  정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...  사실형  긍정   \n",
       "3  TRAIN_00003  서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...  사실형  긍정   \n",
       "4  TRAIN_00004           익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.  사실형  긍정   \n",
       "\n",
       "   시제 확실성         label  \n",
       "0  현재  확실  사실형-긍정-현재-확실  \n",
       "1  과거  확실  사실형-긍정-과거-확실  \n",
       "2  미래  확실  사실형-긍정-미래-확실  \n",
       "3  과거  확실  사실형-긍정-과거-확실  \n",
       "4  현재  확실  사실형-긍정-현재-확실  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = os.getcwd() + '\\\\open'\n",
    "train = os.listdir(folder)[2]\n",
    "test  = os.listdir(folder)[1]\n",
    "submit = os.listdir(folder)[0]\n",
    "\n",
    "train = pd.read_csv(folder + '/' + train)\n",
    "test = pd.read_csv(folder + '/' + test)\n",
    "submit = pd.read_csv(folder + '/' + submit)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "522818df",
   "metadata": {},
   "outputs": [],
   "source": [
    "type1 = train['유형']=='사실형'\n",
    "type2 = train['유형']=='추론형'\n",
    "type3 = train['유형']=='예측형'\n",
    "type4 = train['유형']=='대화형'\n",
    "\n",
    "sent1 = train['극성']=='긍정'\n",
    "sent2 = train['극성']=='부정'\n",
    "sent3 = train['극성']=='미정'\n",
    "\n",
    "tense1 = train['시제']=='현재'\n",
    "tense2 = train['시제']=='과거'\n",
    "tense3 = train['시제']=='미래'\n",
    "\n",
    "certainty1 = train['확실성']=='확실'\n",
    "certainty2 = train['확실성']=='불확실'\n",
    "\n",
    "y1 = np.where(type1, 0, \n",
    "          np.where(type2, 1, \n",
    "          np.where(type3, 2, 3))).tolist()\n",
    "y2 = np.where(sent1, 0,\n",
    "          np.where(sent2, 1, 2)).tolist()\n",
    "y3 = np.where(tense1, 0, \n",
    "          np.where(tense2, 1, 2)).tolist()\n",
    "y4 = np.where(certainty1, 0, 1).tolist()\n",
    "\n",
    "y = pd.DataFrame([y1, y2, y3, y4]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b264e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160107</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>0.276760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.160107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036610</td>\n",
       "      <td>0.189302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000258</td>\n",
       "      <td>0.036610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276760</td>\n",
       "      <td>0.189302</td>\n",
       "      <td>0.216086</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  1.000000  0.160107 -0.000258  0.276760\n",
       "1  0.160107  1.000000  0.036610  0.189302\n",
       "2 -0.000258  0.036610  1.000000  0.216086\n",
       "3  0.276760  0.189302  0.216086  1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유형, 극성, 시제, 확실성\n",
    "y.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5db3db5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. num train : 16541\n",
      "\n",
      "2. null train check : \n",
      "ID       0\n",
      "문장       0\n",
      "유형       0\n",
      "극성       0\n",
      "시제       0\n",
      "확실성      0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "3. unique labels : \n",
      "['사실형' '추론형' '예측형' '대화형']\n",
      "[13558, 2151, 257, 575]\n",
      "['긍정' '부정' '미정']\n",
      "[15793, 565, 183]\n",
      "['현재' '과거' '미래']\n",
      "[6866, 8032, 1643]\n",
      "['확실' '불확실']\n",
      "[15192, 1349]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"1. num train : {len(train)}\\n\")\n",
    "print(f\"2. null train check : \\n{train.isnull().sum()}\\n\")\n",
    "print(f\"3. unique labels : \\n{train.유형.unique()}\\n\\\n",
    "{[len(train[train['유형']==train.유형.unique()[idx]]) for idx in range(len(train.유형.unique()))]}\\n\\\n",
    "{train.극성.unique()}\\n\\\n",
    "{[len(train[train['극성']==train.극성.unique()[idx]]) for idx in range(len(train.극성.unique()))]}\\n\\\n",
    "{train.시제.unique()}\\n\\\n",
    "{[len(train[train['시제']==train.시제.unique()[idx]]) for idx in range(len(train.시제.unique()))]}\\n\\\n",
    "{train.확실성.unique()}\\n\\\n",
    "{[len(train[train['확실성']==train.확실성.unique()[idx]]) for idx in range(len(train.확실성.unique()))]}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd4e3118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반작(봄에 환곡을 나눠줄 때는 주지 않고도 주었다고 하고, 가을에 거두어들일 때는 회수하고도 회수하지 않았다고 해 중간에 이득을 나눔), 입본(농사 상황과 곡식 시세를 살펴서 돈과 곡식 간의 교환을 통해 이득을 챙김), 가집(상급 부서에서 지시한 것보다 더 많은 곡식을 방출하고 남는 것을 횡령), 암류(환곡을 제때에 대출하지 않고 창고에 쌓아 두었다가 값이 오르면 팔고 내리면 사들임), 반백(농민을 속여 대출 때 곡식의 절반을 가로채고 갚을 때는 모두 갚게 함), 분석(곡식에 돌, 쭉정이를 섞어 늘어난 양만큼 횡령), 집신(묵은 곡식은 나눠주고 햇곡식은 자기들이 가짐), 탄정(흉년이 들면 정부에서 환곡의 수량을 감해주는데 백성들에게는 환곡을 전량 징수하고 감액만큼 착복), 세전(환곡으로 받은 곡식과 세금으로 받은 곡식을 이리저리 돌려 이익을 남김), 요합(민간이 부역 대신 곡식으로 납부할 때 거슬러주어야 할 쌀을 횡령), 사흔(아전이 환곡을 징수하면서 자기들의 수고비를 같이 징수), 채륵(아전이 개인 채무까지 환곡과 혼합해 착복)이 그것이다.\n",
      "truncated\n",
      "반작(봄에 환곡을 나눠줄 때는 주지 않고도 주었다고 하고, 가을에 거두어들일 때는 회수하고도 회수하지 않았다고 해 중간에 이득을 나눔), 입본(농사 상황과 납부할 때 거슬러주어야 할 쌀을 횡령), 사흔(아전이 환곡을 징수하면서 자기들의 수고비를 같이 징수), 채륵(아전이 개인 채무까지 환곡과 혼합해 착복)이 그것이다.\n"
     ]
    }
   ],
   "source": [
    "def truncate(texts, data):\n",
    "    truncated_texts = []\n",
    "    for txt in texts:\n",
    "        splited = txt.split(' ')\n",
    "        if len(splited)>=40:\n",
    "            valid = ' '.join(splited[:20] + splited[-20:])\n",
    "            truncated_texts.append(valid)\n",
    "        else:\n",
    "            truncated_texts.append(txt)  \n",
    "    data['문장'] = truncated_texts\n",
    "    print('truncated')\n",
    "    return\n",
    "\n",
    "print(train['문장'][8838])\n",
    "truncate(train['문장'], train)\n",
    "print(train['문장'][8838])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e7941b",
   "metadata": {},
   "source": [
    "## train data 둘러보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train.문장.tolist()\n",
    "len(texts)\n",
    "\n",
    "# 문장 자르기\n",
    "truncated_texts = []\n",
    "for txt in texts:\n",
    "    splited = txt.split(' ')\n",
    "    if len(splited)>=40:\n",
    "        valid = ' '.join(splited[:20] + splited[-20:])\n",
    "        truncated_texts.append(valid)\n",
    "    else:\n",
    "        truncated_texts.append(txt)\n",
    "truncated_texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045babca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for text in tq(texts):\n",
    "    lengths.append(len(text.split(' ')))\n",
    "lengths = pd.DataFrame(sorted(lengths))    \n",
    "lengths[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4638f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for text in tq(truncated_texts):\n",
    "    lengths.append(len(text.split(' ')))\n",
    "lengths = pd.DataFrame(sorted(lengths))    \n",
    "lengths[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a18b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = t.encode_plus(\n",
    "    truncated_texts[8838],\n",
    "    add_special_tokens=True,\n",
    "    max_length= 72, \n",
    "    return_token_type_ids=False,\n",
    "    padding = 'max_length',\n",
    "    truncation = True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1cd4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = AutoModel.from_pretrained(\"klue/roberta-large\").embeddings.word_embeddings.weight\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb08c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbabc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.nn.Embedding(32000, 1024)\n",
    "temp(torch.tensor([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93547ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26deb660",
   "metadata": {},
   "source": [
    "### LSTM encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe0b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(torch.nn.Module):\n",
    "    def __init__(self, I, E, H):\n",
    "        super().__init__()\n",
    "        self.embedding = AutoModel.from_pretrained(\"klue/roberta-large\").embeddings.word_embeddings\n",
    "        self.lstm = torch.nn.LSTM(input_size=E, hidden_size=H, num_layers=3, batch_first=True)\n",
    "        \n",
    "    def forward(self, x_ids:torch.tensor, h, c):\n",
    "        x = self.embedding(x_ids)\n",
    "        hiddens, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        \n",
    "        return hiddens, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f91a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5bc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38441763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e57aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6989c12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLM.embeddings.word_embeddings.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61145c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLM.embeddings.token_type_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44caa24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoding.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[880])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7fbb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "End_tagger = Komoran()\n",
    "NVA_tagger = Okt()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a36b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tagger = Komoran()\n",
    "noun_tagger = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b815631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set([\"라며\",\"전\",\"이\", \"그\", \"저\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea12c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = texts[6]\n",
    "print(cur)\n",
    "cur = cur.split(' ')\n",
    "\n",
    "valid_tokens = []\n",
    "for token in cur:\n",
    "    added_flag = False\n",
    "    \n",
    "    nouns  = noun_tagger.nouns(token)\n",
    "    valids = valid_tagger.pos(token)\n",
    "      \n",
    "    for piece1, piece2 in zip_longest(nouns, valids):\n",
    "        if piece1 is not None:\n",
    "            if(piece1[0] not in stopwords):\n",
    "                valid_tokens.append(piece1)\n",
    "        if (piece2[1][0] == 'V') | (piece2[1][0] == 'X') | (piece2[1] == 'EP') | (piece2[1] == 'EF') | (piece2[1] == 'EC'):\n",
    "            valid_tokens.append(piece2[0])\n",
    "                        \n",
    "print(valid_tokens, \"\\nlen : \",len(valid_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81993089",
   "metadata": {},
   "outputs": [],
   "source": [
    "    nouns  = noun_tagger.nouns(token)\n",
    "    valids = valid_tagger.pos(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_tagger.nouns(texts[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72279483",
   "metadata": {},
   "outputs": [],
   "source": [
    "NVA_tagger.pos(texts[1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452acb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "End_tagger.pos(texts[1800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e6c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00cd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "NVA_tagger.pos('길어오기')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e92e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "End_tagger.pos('리뉴얼했고')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6629ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e092e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NVAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = lambda x : (x[1] =='NNG') | (x[1] == 'NNP')\n",
    "verbs = lambda x : x[1] == 'VV'\n",
    "advs  = lambda x : x[1] == 'VA'\n",
    "ends  = lambda x : (x[1] == 'EF') | (x[1] == 'EC')\n",
    "\n",
    "valid = lambda x : ( nouns(x) | verbs(x) | advs(x) | ends(x) )\n",
    "\n",
    "\n",
    "for elem in out:\n",
    "    if (valid(elem)):\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6db91",
   "metadata": {},
   "source": [
    "## find frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c704800",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
    "noun_ext = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbebb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcounter(data:pd.Series, mode='noun', threshold=30, visible_tqdm = True):\n",
    "    dic = dict()\n",
    "    noun_ext = Okt()\n",
    "\n",
    "    if mode == 'noun':\n",
    "        func = noun_ext.nouns\n",
    "    elif mode == 'pos':\n",
    "        func = noun_ext.pos\n",
    "    else:\n",
    "        func = noun_ext.morphs\n",
    "    \n",
    "    if visible_tqdm is not None:\n",
    "        iterator = tq(enumerate(data), total=len(data))\n",
    "    else:\n",
    "        iterator = enumerate(data)\n",
    "    \n",
    "\n",
    "    for idx, text in iterator:\n",
    "        nouns = func(text)\n",
    "\n",
    "        for word in nouns:\n",
    "            if len(word) <= 1 :\n",
    "                continue \n",
    "            if word in dic:\n",
    "                dic[word] += 1\n",
    "            else:\n",
    "                dic[word] = 1 \n",
    "\n",
    "                    \n",
    "    freq_all = sorted(dic.items(), key = lambda item: item[1], reverse = True)                \n",
    "    freq = []\n",
    "    \n",
    "    # threshold 이하는 다 쳐내\n",
    "    for item in freq_all:\n",
    "        if item[1] < threshold:\n",
    "            continue\n",
    "        freq.append(item)\n",
    "    \n",
    "    freq = freq[:50]\n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878af56d",
   "metadata": {},
   "source": [
    "### frequent words of each \"type\" of text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01fe67",
   "metadata": {},
   "source": [
    "##### (1) 사실형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ded773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "사실형 = train[train['유형']=='사실형']['문장'].tolist()\n",
    "사실형 = wordcounter(사실형, mode=None, visible_tqdm=True)\n",
    "사실형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e157a",
   "metadata": {},
   "source": [
    "##### (2) 추론형 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be068749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "추론형 = train[train['유형']=='추론형']['문장'].tolist()\n",
    "추론형 = wordcounter(추론형, True)\n",
    "추론형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510568e8",
   "metadata": {},
   "source": [
    "##### (3) 예측형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d12702",
   "metadata": {},
   "outputs": [],
   "source": [
    "예측형 = train[train['유형']=='예측형']['문장'].tolist()\n",
    "예측형 = wordcounter(예측형, True)\n",
    "예측형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02df862",
   "metadata": {},
   "source": [
    "##### (4) 대화형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "대화형 = train[train['유형']=='대화형']['문장'].tolist()\n",
    "대화형 = wordcounter(대화형, True)\n",
    "대화형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4518a7",
   "metadata": {},
   "source": [
    "### frequent words of each \"polarity\" of text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6db1b5",
   "metadata": {},
   "source": [
    "##### (1) 긍정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226981c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "긍정 = train[train['극성']=='긍정']['문장'].tolist()\n",
    "긍정 = wordcounter(긍정, mode=None, visible_tqdm=True)\n",
    "긍정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c15a0",
   "metadata": {},
   "source": [
    "##### (2) 부정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "부정 = train[train['극성']=='부정']['문장'].tolist()\n",
    "부정 = wordcounter(부정, mode=None, visible_tqdm=True)\n",
    "부정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa1a7e",
   "metadata": {},
   "source": [
    "##### (3) 미정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068aaf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "미정 = train[train['극성']=='미정']['문장'].tolist()\n",
    "미정 = wordcounter(미정, mode=None, visible_tqdm=True)\n",
    "미정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c3efd",
   "metadata": {},
   "source": [
    "### frequent words of each \"tense\" of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b817fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "현재 = train[train['시제']=='현재']['문장'].tolist()\n",
    "현재 = wordcounter(현재, mode=None, visible_tqdm=True)\n",
    "현재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4694a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "과거 = train[train['시제']=='과거']['문장'].tolist()\n",
    "과거 = wordcounter(과거, mode=None, visible_tqdm=True)\n",
    "과거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab2213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "미래 = train[train['시제']=='미래']['문장'].tolist()\n",
    "미래 = wordcounter(미래, mode=None, visible_tqdm=True)\n",
    "미래"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f17929f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7d34b0e",
   "metadata": {},
   "source": [
    "### check test data\n",
    "- weighted F1 score  \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310370ee",
   "metadata": {},
   "source": [
    "### check submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3bf874",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af139a3",
   "metadata": {},
   "source": [
    "### pretrained model  \n",
    "- 논문으로 공개된 사전 학습 모델(Pre-trained Model) 사용 가능  \n",
    "- KLUE roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, max_len, plm=\"klue/roberta-large\", infer=False):\n",
    "        self.text      = data['문장'].tolist()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(plm)\n",
    "        self.max_len   = max_len\n",
    "        self.infer     = infer\n",
    "        \n",
    "        if self.infer is not None:\n",
    "            type1 = data['유형']=='사실형'\n",
    "            type2 = data['유형']=='추론형'\n",
    "            type3 = data['유형']=='예측형'\n",
    "            type4 = data['유형']=='대화형'\n",
    "            \n",
    "            sent1 = data['극성']=='긍정'\n",
    "            sent2 = data['극성']=='부정'\n",
    "            sent3 = data['극성']=='미정'\n",
    "            \n",
    "            tense1 = data['시제']=='현재'\n",
    "            tense2 = data['시제']=='과거'\n",
    "            tense3 = data['시제']=='미래'\n",
    "            \n",
    "            certainty1 = data['확실성']=='확실'\n",
    "            certainty2 = data['확실성']=='불확실'\n",
    "            \n",
    "            self.y1 = np.where(type1, 0, \n",
    "                      np.where(type2, 1, \n",
    "                      np.where(type3, 2, 3))).tolist()\n",
    "            self.y2 = np.where(sent1, 0,\n",
    "                      np.where(sent2, 1, 2)).tolist()\n",
    "            self.y3 = np.where(tense1, 0, \n",
    "                      np.where(tense2, 1, 2)).tolist()\n",
    "            self.y4 = np.where(certainty1, 0, 1).tolist()\n",
    "                        \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        x_ids, x_attn = [encoding['input_ids'].flatten(), encoding['attention_mask'].flatten()]\n",
    "        if self.infer is not None:\n",
    "            y1 = self.y1[idx]\n",
    "            y2 = self.y2[idx]\n",
    "            y3 = self.y3[idx]\n",
    "            y4 = self.y4[idx]\n",
    "            \n",
    "            ys = torch.tensor([y1,y2,y3,y4]) \n",
    "            return x_ids, x_attn, ys        \n",
    "        else:\n",
    "            return x_ids, x_attn\n",
    "            \n",
    "def get_dataloader(data, batch_size, max_len=256, plm=\"klue/roberta-large\", infer=False, shuffle=True):\n",
    "    return DataLoader(\n",
    "        dataset=CustomDataset(data=data, max_len=max_len, plm=plm, infer=infer),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787188bf",
   "metadata": {},
   "source": [
    "### data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b375fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, plm = \"klue/roberta-large\"):\n",
    "        super().__init__()\n",
    "        self.activate = torch.nn.SiLU()\n",
    "        self.dropout = torch.nn.Dropout(p=0.1)\n",
    "        self.feature_extractor = AutoModel.from_pretrained(plm)\n",
    "        self.feature_extractor.eval() # freeze FE \n",
    "    \n",
    "        self.type_linear      = self.get_cls()\n",
    "        self.polarity_linear  = self.get_cls()\n",
    "        self.tense_linear     = self.get_cls()\n",
    "        self.certainty_linear = self.get_cls()\n",
    "            \n",
    "    def forward(self, x_ids, x_attn):  \n",
    "        \n",
    "        x = self.feature_extractor(input_ids=x_ids, attention_mask=x_attn).to_tuple()[0] [:, 0, :] # cls token\n",
    "                                                                                    # hidden states:0 / last hidden state:1\n",
    "        y1 = self.type_linear(x)\n",
    "        y2 = self.polarity_linear(x)\n",
    "        y3 = self.tense_linear(x)\n",
    "        y4 = self.certainty_linear(x)\n",
    "    \n",
    "        return (y1,y2,y3,y4)\n",
    "\n",
    "    def get_cls(self):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Linear(1024, 768),\n",
    "            torch.nn.LayerNorm(768),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            self.activate,\n",
    "            torch.nn.Linear(768, 256),\n",
    "            torch.nn.LayerNorm(256),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "            self.activate,\n",
    "            torch.nn.Linear(256, 1)\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE':256,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51571c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_dataloader(\n",
    "    data=train,\n",
    "    batch_size=CFG['BATCH_SIZE']\n",
    ")\n",
    "\n",
    "model = Classifier()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d947b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterions = [torch.nn.CrossEntropyLoss() for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf471ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = model.to(device)\n",
    "criterions = [torch.nn.CrossEntropyLoss().to(device) for _ in range(4)]\n",
    "\n",
    "for epoch in range(1, CFG['EPOCHS']+1):\n",
    "    model.train()\n",
    "    train_loss=[]\n",
    "    for x_ids, x_attn, y in tq(train_loader):\n",
    "        x_ids, x_attn, y = x_ids.to(device), x_attn.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        yhat0, yhat1, yhat2, yhat3 = model(x_ids, x_attn)\n",
    "        \n",
    "        loss1 = 0.25*criterions[0](yhat0, y[0])\n",
    "        loss2 = 0.25*criterions[1](yhat1, y[1])\n",
    "        loss3 = 0.25*criterions[2](yhat2, y[2])\n",
    "        loss4 = 0.25*criterions[3](yhat3, y[3])\n",
    "        \n",
    "        loss = loss1+loss2+loss3+loss4\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ed1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tch",
   "language": "python",
   "name": "tch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
